{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "patentSearchCosineCode.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgFtfevQvIHS",
        "colab_type": "code",
        "outputId": "1dd8019a-d6bd-43bd-b385-0c1d9833cc34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1722
        }
      },
      "source": [
        "!git clone https://github.com/jcnrn/usptoSearch.git\n",
        "!pip install autocorrect\n",
        "!pip3 install fuzzywuzzy[speedup]\n",
        "!pip install uspto-opendata-python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'usptoSearch'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n",
            "Collecting autocorrect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/b6/6c74ff19249dc6d7285541cd59f5a3edbbd0f7209362a63e314fc09b2636/autocorrect-0.3.0.tar.gz (3.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.6MB 6.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Running setup.py bdist_wheel for autocorrect ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bf/b8/ae/704d5643f1d0637c5b87d9feccf2ee923c492b703bb0bfbb19\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-0.3.0\n",
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Collecting python-levenshtein>=0.12; extra == \"speedup\" (from fuzzywuzzy[speedup])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup]) (40.6.2)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Running setup.py bdist_wheel for python-levenshtein ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein, fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.17.0 python-levenshtein-0.12.0\n",
            "Collecting uspto-opendata-python\n",
            "  Downloading https://files.pythonhosted.org/packages/70/59/0cca2b87fac371fc45bc71059477de04f741fb3d6d6eaf9b29d64717f4c6/uspto-opendata-python-0.8.2.tar.gz\n",
            "Collecting celery==4.1.0 (from uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/9b/88ef5cc7edf5d43215f383ae0a2b1cdeb33f5f07886386c7e4691b2eba0c/celery-4.1.0-py2.py3-none-any.whl (400kB)\n",
            "\u001b[K    100% |████████████████████████████████| 409kB 22.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.18.4 in /usr/local/lib/python3.6/dist-packages (from uspto-opendata-python) (2.18.4)\n",
            "Collecting redis==2.10.6 (from uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/f6/7a76333cf0b9251ecf49efff635015171843d9b977e4ffcf59f9c4428052/redis-2.10.6-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 23.6MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0 (from uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt==0.6.2 in /usr/local/lib/python3.6/dist-packages (from uspto-opendata-python) (0.6.2)\n",
            "Collecting pathvalidate==0.16.2 (from uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/35/b1d83195cafa6a51422f2caf8cd365adc93863181a3ec3759e03b89117b7/pathvalidate-0.16.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml==4.2.5 in /usr/local/lib/python3.6/dist-packages (from uspto-opendata-python) (4.2.5)\n",
            "Collecting jsonpointer==1.12 (from uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/de/bad0b57fd1271974db34adef33c22d42249011fe5aaacb99b7345adfdb5f/jsonpointer-1.12-py2.py3-none-any.whl\n",
            "Collecting clint==0.5.1 (from uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/b4/41ecb1516f1ba728f39ee7062b9dac1352d39823f513bb6f9e8aeb86e26d/clint-0.5.1.tar.gz\n",
            "Collecting awesome-slugify==1.6.5 (from uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/34/39/79ef4e640c3651b40de7812f5fcd04698abf14de4f57a81e12b6c753d168/awesome-slugify-1.6.5.tar.gz\n",
            "Collecting billiard<3.6.0,>=3.5.0.2 (from celery==4.1.0->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/b7/c2fe04f2522bb02d044347734eeda3ff5c7a632fa7d0401530a371ba73db/billiard-3.5.0.5.tar.gz (150kB)\n",
            "\u001b[K    100% |████████████████████████████████| 153kB 29.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>dev in /usr/local/lib/python3.6/dist-packages (from celery==4.1.0->uspto-opendata-python) (2018.7)\n",
            "Collecting kombu<5.0,>=4.0.2 (from celery==4.1.0->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/25/036ef6c8e383832d6b8e1e34429daf12af577ef57cda0a402383aa026e24/kombu-4.2.2-py2.py3-none-any.whl (182kB)\n",
            "\u001b[K    100% |████████████████████████████████| 184kB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.18.4->uspto-opendata-python) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.18.4->uspto-opendata-python) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.18.4->uspto-opendata-python) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.18.4->uspto-opendata-python) (2.6)\n",
            "Collecting args (from clint==0.5.1->uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/1c/b701b3f4bd8d3667df8342f311b3efaeab86078a840fb826bd204118cc6b/args-0.1.0.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from awesome-slugify==1.6.5->uspto-opendata-python) (2018.1.10)\n",
            "Collecting Unidecode<0.05,>=0.04.14 (from awesome-slugify==1.6.5->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/a1/9d7f3138ee3d79a1ab865a2cb38200ca778d85121db19fe264c76c981184/Unidecode-0.04.21-py2.py3-none-any.whl (228kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 27.3MB/s \n",
            "\u001b[?25hCollecting amqp<3.0,>=2.1.4 (from kombu<5.0,>=4.0.2->celery==4.1.0->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/cf/12d4611fc67babd4ae250c9e8249c5650ae1933395488e9e7e3562b4ff24/amqp-2.3.2-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 20.5MB/s \n",
            "\u001b[?25hCollecting vine>=1.1.3 (from amqp<3.0,>=2.1.4->kombu<5.0,>=4.0.2->celery==4.1.0->uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/10/50/5b1ebe42843c19f35edb15022ecae339fbec6db5b241a7a13c924dabf2a3/vine-1.1.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: uspto-opendata-python, clint, awesome-slugify, billiard, args\n",
            "  Running setup.py bdist_wheel for uspto-opendata-python ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b1/94/b6/c6b77bd610359b2b0a006813a38a41213cc6a3ce9f944f73c5\n",
            "  Running setup.py bdist_wheel for clint ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/4f/e9/45/223565e5b1a4b09e12c6de6f8ba7c2c0e9127dec17cf830f83\n",
            "  Running setup.py bdist_wheel for awesome-slugify ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e9/d9/66/bde66382496710218c0df31b5f3a72bd8079bcd275fff61b29\n",
            "  Running setup.py bdist_wheel for billiard ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b8/72/0e/39ecdedc4cfc45b693a623732e40dbd4cff5ea5e11775ee591\n",
            "  Running setup.py bdist_wheel for args ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/58/54/ea/d995d18af68c057eb76b87b02c92bc66ac34d360ef141780f4\n",
            "Successfully built uspto-opendata-python clint awesome-slugify billiard args\n",
            "Installing collected packages: billiard, vine, amqp, kombu, celery, redis, beautifulsoup4, pathvalidate, jsonpointer, args, clint, Unidecode, awesome-slugify, uspto-opendata-python\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: Unidecode 1.0.23\n",
            "    Uninstalling Unidecode-1.0.23:\n",
            "      Successfully uninstalled Unidecode-1.0.23\n",
            "Successfully installed Unidecode-0.4.21 amqp-2.3.2 args-0.1.0 awesome-slugify-1.6.5 beautifulsoup4-4.6.0 billiard-3.5.0.5 celery-4.1.0 clint-0.5.1 jsonpointer-1.12 kombu-4.2.2 pathvalidate-0.16.2 redis-2.10.6 uspto-opendata-python-0.8.2 vine-1.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6UnJ9c-icrX",
        "colab_type": "code",
        "outputId": "9073cf08-692a-4b04-ffa6-605e7cb2e5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "import os\n",
        "import nltk.data\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "import itertools\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "from autocorrect import spell \n",
        "\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "import requests\n",
        "from pandas.io.json import json_normalize\n",
        "import json\n",
        "\n",
        "os.chdir('/content/usptoSearch')\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/usptoSearch'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUauuRCSmAu6",
        "colab_type": "code",
        "outputId": "a27d1f0c-8831-4d2c-9c95-b8b8c95ae235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "#import data\n",
        "df = pd.read_csv('usptoSubsetData.csv')\n",
        "print(len(df))\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat_no</th>\n",
              "      <th>claim_no</th>\n",
              "      <th>claim_txt</th>\n",
              "      <th>dependencies</th>\n",
              "      <th>ind_flg</th>\n",
              "      <th>appl_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>2</td>\n",
              "      <td>2. The process of claim 1, wherein in process ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039651</td>\n",
              "      <td>1</td>\n",
              "      <td>1. In the process for the production of hydrog...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4039652</td>\n",
              "      <td>23</td>\n",
              "      <td>23. A method as in claim 1 wherein said substa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5405316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4039652</td>\n",
              "      <td>29</td>\n",
              "      <td>29. A method as in claim 26 wherein said immob...</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>5405316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4039652</td>\n",
              "      <td>24</td>\n",
              "      <td>24. A method as in claim 23 wherein said subst...</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>5405316.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pat_no  claim_no                                          claim_txt  \\\n",
              "0  4039651         2  2. The process of claim 1, wherein in process ...   \n",
              "1  4039651         1  1. In the process for the production of hydrog...   \n",
              "2  4039652        23  23. A method as in claim 1 wherein said substa...   \n",
              "3  4039652        29  29. A method as in claim 26 wherein said immob...   \n",
              "4  4039652        24  24. A method as in claim 23 wherein said subst...   \n",
              "\n",
              "  dependencies  ind_flg    appl_id  \n",
              "0            1        0        NaN  \n",
              "1          NaN        1        NaN  \n",
              "2            1        0  5405316.0  \n",
              "3           26        0  5405316.0  \n",
              "4           23        0  5405316.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC7l1cr-y9V5",
        "colab_type": "code",
        "outputId": "7fb696db-fb0f-41f9-fe4d-0a8ddb281ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df1=df.copy()\n",
        "#concatenate claims by patent number\n",
        "df2 = df1.sort_values(['pat_no', 'claim_no']).groupby('pat_no', sort=False).claim_txt.apply(' '.join).reset_index(name='concat_claims')\n",
        "df2.to_csv('concatenated.csv')\n",
        "print(len(df))\n",
        "df2.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat_no</th>\n",
              "      <th>concat_claims</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>1. In the process for the production of hydrog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039652</td>\n",
              "      <td>1. A method for the quantitative determination...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4039653</td>\n",
              "      <td>1. A tablet for releasing a relatively uniform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4039654</td>\n",
              "      <td>1. A prostanoic acid derivative of the formula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4039655</td>\n",
              "      <td>1. A composition of matter useful in caries pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pat_no                                      concat_claims\n",
              "0  4039651  1. In the process for the production of hydrog...\n",
              "1  4039652  1. A method for the quantitative determination...\n",
              "2  4039653  1. A tablet for releasing a relatively uniform...\n",
              "3  4039654  1. A prostanoic acid derivative of the formula...\n",
              "4  4039655  1. A composition of matter useful in caries pr..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zj2g3NI5XEt",
        "colab_type": "code",
        "outputId": "af9ecad7-16de-4b90-e8a5-7fa5bcd935eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "len(df2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP-Tcg6dmMj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ieq_q8VknkI",
        "colab_type": "code",
        "outputId": "372450c0-dba9-4f78-92e9-d28a36c5a8ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df3 = df2.copy()\n",
        "df3['processed'] = df3['concat_claims']\n",
        "\n",
        "#preprocess data\n",
        "stemmer = SnowballStemmer('english')   #snowball stemmer chosen over porter due for its aggressiveness\n",
        "\n",
        "#preprocess data\n",
        "df3['processed'] = df3['processed'].str.replace('\\d+', '') #remove digits\n",
        "df3['processed'] = df3['processed'].str.replace('[^\\w\\s]','') #remove punctuation\n",
        "df3['processed'] = df3['processed'].str.lower() #lowercase\n",
        "#df3['processed'] = df3['processed'].apply(lambda x: \" \".join([spell(i) for i in x.split()]))   #spellcheck             #computationally too intensive\n",
        "df3['processed']= df3['processed'].apply(treebank_tokenizer.tokenize) #tokenize\n",
        "df3['processed'] = df3['processed'].apply(lambda x: [y for y in x if y not in stop]) #remove stop words\n",
        "#df3['processed'] = df3['processed'].apply(lambda x: [wordnet_lemmatizer.lemmatize(item) for item in x]) #lemmatize    #stemming chosen over lemmatize\n",
        "df3['processed'] = df3['processed'].apply(lambda x: [stemmer.stem(item) for item in x]) #stem\n",
        "df3.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat_no</th>\n",
              "      <th>concat_claims</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>1. In the process for the production of hydrog...</td>\n",
              "      <td>[process, product, hydrogen, oxygen, water, me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039652</td>\n",
              "      <td>1. A method for the quantitative determination...</td>\n",
              "      <td>[method, quantit, determin, specif, bind, subs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4039653</td>\n",
              "      <td>1. A tablet for releasing a relatively uniform...</td>\n",
              "      <td>[tablet, releas, relat, uniform, quantiti, med...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4039654</td>\n",
              "      <td>1. A prostanoic acid derivative of the formula...</td>\n",
              "      <td>[prostano, acid, deriv, formula, str, wherein,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4039655</td>\n",
              "      <td>1. A composition of matter useful in caries pr...</td>\n",
              "      <td>[composit, matter, use, cari, prevent, compris...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pat_no                                      concat_claims  \\\n",
              "0  4039651  1. In the process for the production of hydrog...   \n",
              "1  4039652  1. A method for the quantitative determination...   \n",
              "2  4039653  1. A tablet for releasing a relatively uniform...   \n",
              "3  4039654  1. A prostanoic acid derivative of the formula...   \n",
              "4  4039655  1. A composition of matter useful in caries pr...   \n",
              "\n",
              "                                           processed  \n",
              "0  [process, product, hydrogen, oxygen, water, me...  \n",
              "1  [method, quantit, determin, specif, bind, subs...  \n",
              "2  [tablet, releas, relat, uniform, quantiti, med...  \n",
              "3  [prostano, acid, deriv, formula, str, wherein,...  \n",
              "4  [composit, matter, use, cari, prevent, compris...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncGRhwOo6OOk",
        "colab_type": "code",
        "outputId": "b49823b4-6d56-49b2-a209-0bedad716e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#create keyword list of 40 of the most commonly used words\n",
        "df4=df3.copy()\n",
        "df4['keywords'] = df4['processed'].apply(lambda x: [k for k, v in Counter(x).most_common(30)])\n",
        "dfIndex = df4\n",
        "dfIndex.to_csv('patentIndex.csv')\n",
        "#dfIndex = df4.drop(['concat_claims'], axis=1)\n",
        "dfIndex.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat_no</th>\n",
              "      <th>concat_claims</th>\n",
              "      <th>processed</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>1. In the process for the production of hydrog...</td>\n",
              "      <td>[process, product, hydrogen, oxygen, water, me...</td>\n",
              "      <td>[iron, oxid, chlorid, step, ii, process, hydro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039652</td>\n",
              "      <td>1. A method for the quantitative determination...</td>\n",
              "      <td>[method, quantit, determin, specif, bind, subs...</td>\n",
              "      <td>[said, matrix, sampl, wherein, method, predete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4039653</td>\n",
              "      <td>1. A tablet for releasing a relatively uniform...</td>\n",
              "      <td>[tablet, releas, relat, uniform, quantiti, med...</td>\n",
              "      <td>[tablet, said, materi, medica, releas, odormas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4039654</td>\n",
              "      <td>1. A prostanoic acid derivative of the formula...</td>\n",
              "      <td>[prostano, acid, deriv, formula, str, wherein,...</td>\n",
              "      <td>[rsup, acid, prostano, deriv, hydrogen, claim,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4039655</td>\n",
              "      <td>1. A composition of matter useful in caries pr...</td>\n",
              "      <td>[composit, matter, use, cari, prevent, compris...</td>\n",
              "      <td>[group, compound, said, composit, oral, german...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pat_no                                      concat_claims  \\\n",
              "0  4039651  1. In the process for the production of hydrog...   \n",
              "1  4039652  1. A method for the quantitative determination...   \n",
              "2  4039653  1. A tablet for releasing a relatively uniform...   \n",
              "3  4039654  1. A prostanoic acid derivative of the formula...   \n",
              "4  4039655  1. A composition of matter useful in caries pr...   \n",
              "\n",
              "                                           processed  \\\n",
              "0  [process, product, hydrogen, oxygen, water, me...   \n",
              "1  [method, quantit, determin, specif, bind, subs...   \n",
              "2  [tablet, releas, relat, uniform, quantiti, med...   \n",
              "3  [prostano, acid, deriv, formula, str, wherein,...   \n",
              "4  [composit, matter, use, cari, prevent, compris...   \n",
              "\n",
              "                                            keywords  \n",
              "0  [iron, oxid, chlorid, step, ii, process, hydro...  \n",
              "1  [said, matrix, sampl, wherein, method, predete...  \n",
              "2  [tablet, said, materi, medica, releas, odormas...  \n",
              "3  [rsup, acid, prostano, deriv, hydrogen, claim,...  \n",
              "4  [group, compound, said, composit, oral, german...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J28OD_3fGmy9",
        "colab_type": "code",
        "outputId": "a8abeb17-9c63-49d5-8862-4b7a70253db0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#rawSearch=(input('Enter your search:'))\n",
        "rawSearch = 'Liquid Crystal Displlaying 1$'\n",
        "\n",
        "\n",
        "def searchPreprocessing(rawSearch):\n",
        "  stemmer = SnowballStemmer('english')\n",
        "  \n",
        "  searchQuery = rawSearch\n",
        "  searchQuery = searchQuery.lower()\n",
        "  searchQuery = ' '.join(map(spell, searchQuery.split()))\n",
        "  searchQuery = searchQuery.replace('[^\\w\\s]','')\n",
        "  searchQuery = searchQuery.replace('\\d+', '')\n",
        "  searchQuery = searchQuery.lower()\n",
        "  searchQuery = treebank_tokenizer.tokenize(searchQuery)\n",
        "  searchQuery = [word for word in searchQuery if word not in stopwords.words('english')]\n",
        "  searchQuery = [stemmer.stem(word) for word in searchQuery]\n",
        "  \n",
        "  print(\"Searching '\" + str(rawSearch) + \"' as: \" + str(searchQuery))\n",
        "  return searchQuery\n",
        "  \n",
        "\n",
        "searchQuery = searchPreprocessing(rawSearch)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching 'Liquid Crystal Displlaying 1$' as: ['liquid', 'crystal', 'display']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWtG7U8gaYyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8EK_iUN-BSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define cosine similarity function\n",
        "def cosine_similarity(document_1_data, document_2_data):\n",
        "    def stringify(whatever):\n",
        "        newString = \" \".join(whatever)\n",
        "        return newString\n",
        "    \n",
        "    \n",
        "    WORD = re.compile(r'\\w+') \n",
        "    \n",
        "    def get_cosine(vec1, vec2):\n",
        "        intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "        numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "        sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "        sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "        denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "        \n",
        "        if not denominator:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return float(numerator) / denominator\n",
        "        \n",
        "    def text_to_vector(text):\n",
        "        words = WORD.findall(text)\n",
        "        return Counter(words)\n",
        "    \n",
        "    text1 = stringify(document_1_data)\n",
        "    text2 = stringify(document_2_data)\n",
        "    \n",
        "    vector1 = text_to_vector(text1)\n",
        "    vector2 = text_to_vector(text2)\n",
        "    \n",
        "    cosine = get_cosine(vector1, vector2)\n",
        "    \n",
        "    return(cosine)\n",
        "\n",
        "    \n",
        "#test   \n",
        "#doc1=searchQuery\n",
        "#doc2=dfIndex.iloc[0,1]\n",
        "#cosine_similarity(doc1, doc2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guET-mR2CLwG",
        "colab_type": "code",
        "outputId": "b33bf3ba-b0f1-4be3-c661-90f27bedb3f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "#find cosine values and rank them\n",
        "searchRank = []\n",
        "doc1=searchQuery\n",
        "\n",
        "for index, row in dfIndex.iterrows():\n",
        "  doc2 = dfIndex.iloc[index,1]\n",
        "  procesCos = (cosine_similarity(doc1,doc2))\n",
        "  doc2 = dfIndex.iloc[index,2]\n",
        "  keyworCos = (cosine_similarity(doc1,doc2))\n",
        "  temp = (dfIndex.iloc[index,0], procesCos, keyworCos)\n",
        "  searchRank.append(temp)\n",
        "\n",
        "\n",
        "searchRank=pd.DataFrame(searchRank ,columns=['patNo', 'processedCosRank', 'keywordCosRank'])\n",
        "\n",
        "\n",
        "#rank by processed tokens\n",
        "searchRank = searchRank.sort_values(by=['processedCosRank'], ascending=False)\n",
        "#rank by keyword matches\n",
        "#searchRank = searchRank.sort_values(by=['keywordCosRank'], ascending=False)\n",
        "searchRank.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patNo</th>\n",
              "      <th>processedCosRank</th>\n",
              "      <th>keywordCosRank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>4040375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>4040381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>4040380</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>4040379</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>4040378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>4040377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>4040376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>4040374</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039652</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       patNo  processedCosRank  keywordCosRank\n",
              "0    4039651               0.0         0.00000\n",
              "723  4040375               0.0         0.00000\n",
              "729  4040381               0.0         0.00000\n",
              "728  4040380               0.0         0.00000\n",
              "727  4040379               0.0         0.00000\n",
              "726  4040378               0.0         0.00000\n",
              "725  4040377               0.0         0.00000\n",
              "724  4040376               0.0         0.00000\n",
              "722  4040374               0.0         0.00000\n",
              "1    4039652               0.0         0.07705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PQ_Zuy1yaWn",
        "colab_type": "code",
        "outputId": "9a0825a5-9cad-4cf6-b8bb-d5c80f15418f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "patNo = str(searchRank.iloc[0,0])\n",
        "\n",
        "url = 'http://www.patentsview.org/api/patents/query?q={\"patent_number\":\"'+ patNo + '\"}&f=[\"inventor_first_name\",\"inventor_last_name\",\"patent_number\", \"patent_title\", \"assignee_country\",\"assignee_organization\", \"examiner_id\", \"examiner_last_name\"]'\n",
        "\n",
        "r = requests.get(url)\n",
        "json_data = r.json()\n",
        "\n",
        "for r in json_data['patents']:\n",
        "    print(r)\n",
        "\n",
        "print(json.dumps(json_data, sort_keys=True, indent=0))\n",
        "\n",
        "print('Full Text:')\n",
        "fullText = df2.loc[df2['pat_no'] == int(patNo),'concat_claims']\n",
        "print(list(fullText))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'patent_number': '4039651', 'patent_title': 'Process for closed-cycle thermochemical production of hydrogen and oxygen from water', 'inventors': [{'inventor_first_name': 'Karl-Friedrich', 'inventor_last_name': 'Knoche', 'inventor_key_id': '109512'}, {'inventor_first_name': 'Johannes', 'inventor_last_name': 'Schubert', 'inventor_key_id': '123680'}, {'inventor_first_name': 'Roland', 'inventor_last_name': 'Schulze-Bentrop', 'inventor_key_id': '123681'}], 'assignees': [{'assignee_country': 'DE', 'assignee_organization': 'Rheinische Braunkohlwerke AG', 'assignee_key_id': '86529'}], 'examiners': [{'examiner_id': 'rc6z7a7ydz941xjgwfgx1mwio', 'examiner_last_name': 'Thomas'}]}\n",
            "{\n",
            "\"count\": 1,\n",
            "\"patents\": [\n",
            "{\n",
            "\"assignees\": [\n",
            "{\n",
            "\"assignee_country\": \"DE\",\n",
            "\"assignee_key_id\": \"86529\",\n",
            "\"assignee_organization\": \"Rheinische Braunkohlwerke AG\"\n",
            "}\n",
            "],\n",
            "\"examiners\": [\n",
            "{\n",
            "\"examiner_id\": \"rc6z7a7ydz941xjgwfgx1mwio\",\n",
            "\"examiner_last_name\": \"Thomas\"\n",
            "}\n",
            "],\n",
            "\"inventors\": [\n",
            "{\n",
            "\"inventor_first_name\": \"Karl-Friedrich\",\n",
            "\"inventor_key_id\": \"109512\",\n",
            "\"inventor_last_name\": \"Knoche\"\n",
            "},\n",
            "{\n",
            "\"inventor_first_name\": \"Johannes\",\n",
            "\"inventor_key_id\": \"123680\",\n",
            "\"inventor_last_name\": \"Schubert\"\n",
            "},\n",
            "{\n",
            "\"inventor_first_name\": \"Roland\",\n",
            "\"inventor_key_id\": \"123681\",\n",
            "\"inventor_last_name\": \"Schulze-Bentrop\"\n",
            "}\n",
            "],\n",
            "\"patent_number\": \"4039651\",\n",
            "\"patent_title\": \"Process for closed-cycle thermochemical production of hydrogen and oxygen from water\"\n",
            "}\n",
            "],\n",
            "\"total_patent_count\": 1\n",
            "}\n",
            "Full Text:\n",
            "['1. In the process for the production of hydrogen and oxygen from water by means of a thermochemical closed-cycle multi-step process conducted at temperatures of between about 130.degree. - 1100.degree. C. utilizing at least one member selected from the group consisting of iron oxides, iron chlorides, chlorine and hydrogen chloride as an auxiliary compound, the improvement which comprises employing the steps of:a. reacting water with a member selected from the group consisting of iron and iron (II) oxide at a temperature between 300.degree.-1000.degree. C. in one process step thereby forming hydrogen and a member selected from the group consisting of iron (II, III) oxide and iron (II) oxide, separating and recovering the thus obtained reaction products;b. reacting at least part of the iron oxide formed in step (a) with hydrogen chloride at a temperature of between about 130.degree. - 830.degree. C. in a subsequent process step thereby forming a member selected from the group consisting of iron (II) chloride and iron (III) chloride, separating and recovering the thus obtained reaction products;c. re-forming the starting material selected from the group consisting of iron and iron (II) oxide for process step (a) by converting at least one of said iron chlorides obtained in step (b) to said iron or iron (II) oxide in at least two additional process steps one of the steps being the reaction of a compound selected from the group consisting of iron (II) oxide, iron (II, III) oxide and water with chlorine at a temperature of between about 450.degree. - 1050.degree. C., whereby iron (III) chloride or hydrogen chloride and oxygen are formed, and the second step being the reaction of iron (II) chloride with hydrogen or water, whereby hydrogen chloride is obtained, employing in any further reaction as reactant at least one member selected from the group consisting of iron oxides, iron (III) chloride, chlorine and water, and recycling the so obtained iron or iron (II) oxide into process step (a);d. separating and recovering at least part of said hydrogen formed in step (a) and oxygen as end products. 2. The process of claim 1, wherein in process step (b) iron (II, III) oxide is reacted with a mixture of hydrogen chloride and chlorine.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXw9erR9LpS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for more information\n",
        "#https://courses.cs.washington.edu/courses/cse573/12sp/lectures/17-ir.pdf\n",
        "#https://docs.ip-tools.org/uspto-opendata-python/peds.html\n",
        "#https://bergvca.github.io/2017/10/14/super-fast-string-matching.html\n",
        "#https://stackoverflow.com/questions/15173225/calculate-cosine-similarity-given-2-sentence-strings?rq=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKyJg9aS_jFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn-kOEAnuvbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#junk\n",
        "#df.loc[[False] + list(df.set_index('pat_no').index.get_loc(0))[:-1], 'claim_txt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZPkmhYXCfwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keywords = dfIndex['keywords']\n",
        "#keywords.head()\n",
        "\n",
        "#fuzzywuzzy keyword matching not great\n",
        "#process.extract(str(searchQuery), keywords, limit=4, scorer=fuzz.token_sort_ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P9bZcGgxhoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Doesn't work on many patents. Using PatentView API Instead\n",
        "#from uspto.peds.client import UsptoPatentExaminationDataSystemClient\n",
        "#client = UsptoPatentExaminationDataSystemClient()\n",
        "\n",
        "#result = client.download_document('3987485')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}