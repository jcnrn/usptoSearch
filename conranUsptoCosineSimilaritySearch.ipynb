{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conranUsptoCosineSimilaritySearch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcnrn/usptoSearch/blob/master/conranUsptoCosineSimilaritySearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgFtfevQvIHS",
        "colab_type": "code",
        "outputId": "c0b3b2cf-e696-47b6-cbe2-bf6d8d959574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/jcnrn/usptoSearch.git\n",
        "!pip install autocorrect\n",
        "!pip3 install fuzzywuzzy[speedup]\n",
        "!pip install uspto-opendata-python"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'usptoSearch'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 23 (delta 7), reused 0 (delta 0), pack-reused 6\u001b[K\n",
            "Unpacking objects: 100% (23/23), done.\n",
            "Collecting autocorrect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/b6/6c74ff19249dc6d7285541cd59f5a3edbbd0f7209362a63e314fc09b2636/autocorrect-0.3.0.tar.gz (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 5.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-0.3.0-cp36-none-any.whl size=3602220 sha256=a8c75ed76c13318c62398ad9a421905657e11d1cef4c422c642e6fcdee67023d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/b8/ae/704d5643f1d0637c5b87d9feccf2ee923c492b703bb0bfbb19\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-0.3.0\n",
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Collecting python-levenshtein>=0.12; extra == \"speedup\" (from fuzzywuzzy[speedup])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup]) (41.2.0)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144673 sha256=28dbfd43c3b2b4ad98f1b9a6bbd6f5f1d778c8fdfe6d2f6f615ea179498cdd8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein, fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.17.0 python-levenshtein-0.12.0\n",
            "Collecting uspto-opendata-python\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/8a/1d32a52c2af8250a984bca8bd4f842e11d83316405af3d03c77b54b276ae/uspto-opendata-python-0.8.3.tar.gz\n",
            "Collecting celery==4.1.0 (from uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/9b/88ef5cc7edf5d43215f383ae0a2b1cdeb33f5f07886386c7e4691b2eba0c/celery-4.1.0-py2.py3-none-any.whl (400kB)\n",
            "\u001b[K     |████████████████████████████████| 409kB 7.0MB/s \n",
            "\u001b[?25hCollecting requests==2.18.4 (from uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/df/50aa1999ab9bde74656c2919d9c0c085fd2b3775fd3eca826012bef76d8c/requests-2.18.4-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 31.5MB/s \n",
            "\u001b[?25hCollecting redis==2.10.6 (from uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/f6/7a76333cf0b9251ecf49efff635015171843d9b977e4ffcf59f9c4428052/redis-2.10.6-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 26.2MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0 (from uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt==0.6.2 in /usr/local/lib/python3.6/dist-packages (from uspto-opendata-python) (0.6.2)\n",
            "Collecting pathvalidate==0.16.2 (from uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/35/b1d83195cafa6a51422f2caf8cd365adc93863181a3ec3759e03b89117b7/pathvalidate-0.16.2-py2.py3-none-any.whl\n",
            "Collecting lxml==4.2.5 (from uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a4/9eea8035fc7c7670e5eab97f34ff2ef0ddd78a491bf96df5accedb0e63f5/lxml-4.2.5-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8MB 18.2MB/s \n",
            "\u001b[?25hCollecting jsonpointer==1.12 (from uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/de/bad0b57fd1271974db34adef33c22d42249011fe5aaacb99b7345adfdb5f/jsonpointer-1.12-py2.py3-none-any.whl\n",
            "Collecting clint==0.5.1 (from uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/b4/41ecb1516f1ba728f39ee7062b9dac1352d39823f513bb6f9e8aeb86e26d/clint-0.5.1.tar.gz\n",
            "Collecting awesome-slugify==1.6.5 (from uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/34/39/79ef4e640c3651b40de7812f5fcd04698abf14de4f57a81e12b6c753d168/awesome-slugify-1.6.5.tar.gz\n",
            "Requirement already satisfied: pytz>dev in /usr/local/lib/python3.6/dist-packages (from celery==4.1.0->uspto-opendata-python) (2018.9)\n",
            "Collecting billiard<3.6.0,>=3.5.0.2 (from celery==4.1.0->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/b7/c2fe04f2522bb02d044347734eeda3ff5c7a632fa7d0401530a371ba73db/billiard-3.5.0.5.tar.gz (150kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 41.1MB/s \n",
            "\u001b[?25hCollecting kombu<5.0,>=4.0.2 (from celery==4.1.0->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/22/58104fd214fb32008f2f4d64a1918c81e353f23e7beee9605674f9ecd6b2/kombu-4.6.4-py2.py3-none-any.whl (182kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 43.7MB/s \n",
            "\u001b[?25hCollecting idna<2.7,>=2.5 (from requests==2.18.4->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/cc/6dd9a3869f15c2edfab863b992838277279ce92663d334df9ecf5106f5c6/idna-2.6-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 25.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.18.4->uspto-opendata-python) (2019.6.16)\n",
            "Collecting urllib3<1.23,>=1.21.1 (from requests==2.18.4->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/cb/6965947c13a94236f6d4b8223e21beb4d576dc72e8130bd7880f600839b8/urllib3-1.22-py2.py3-none-any.whl (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.18.4->uspto-opendata-python) (3.0.4)\n",
            "Collecting args (from clint==0.5.1->uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/1c/b701b3f4bd8d3667df8342f311b3efaeab86078a840fb826bd204118cc6b/args-0.1.0.tar.gz\n",
            "Collecting regex (from awesome-slugify==1.6.5->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 40.9MB/s \n",
            "\u001b[?25hCollecting Unidecode<0.05,>=0.04.14 (from awesome-slugify==1.6.5->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/a1/9d7f3138ee3d79a1ab865a2cb38200ca778d85121db19fe264c76c981184/Unidecode-0.04.21-py2.py3-none-any.whl (228kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 43.7MB/s \n",
            "\u001b[?25hCollecting amqp<3.0,>=2.5.1 (from kombu<5.0,>=4.0.2->celery==4.1.0->uspto-opendata-python)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/ef/a62ff9dde89e6b75976a746aa5b828ccb3c839ac6fcdc283edd88d7cf90b/amqp-2.5.1-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 23.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.18 in /usr/local/lib/python3.6/dist-packages (from kombu<5.0,>=4.0.2->celery==4.1.0->uspto-opendata-python) (0.19)\n",
            "Collecting vine<5.0.0a1,>=1.1.3 (from amqp<3.0,>=2.5.1->kombu<5.0,>=4.0.2->celery==4.1.0->uspto-opendata-python)\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/60/82c03047396126c8331ceb64da1dc52d4f1317209f32e8fe286d0c07365a/vine-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.18->kombu<5.0,>=4.0.2->celery==4.1.0->uspto-opendata-python) (0.6.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.18->kombu<5.0,>=4.0.2->celery==4.1.0->uspto-opendata-python) (7.2.0)\n",
            "Building wheels for collected packages: uspto-opendata-python, clint, awesome-slugify, billiard, args, regex\n",
            "  Building wheel for uspto-opendata-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uspto-opendata-python: filename=uspto_opendata_python-0.8.3-cp36-none-any.whl size=25800 sha256=09ebe33e2709f222bf0988cba59dbc91a33395bd1814e27401dcb84daaaddf23\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/22/f5/7eabed513424df0f11c4fe88f34b7a81e53b188f4b573d02c0\n",
            "  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clint: filename=clint-0.5.1-cp36-none-any.whl size=34448 sha256=56cfc6b88124ee6000a6ec715915c6a42bbc2c26626f1d057e6f0105224e9fa3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/e9/45/223565e5b1a4b09e12c6de6f8ba7c2c0e9127dec17cf830f83\n",
            "  Building wheel for awesome-slugify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for awesome-slugify: filename=awesome_slugify-1.6.5-cp36-none-any.whl size=8351 sha256=a3097cea61c520bf2ccc1b983d8f6ea6226c89c09db286e801f227a3a3a22252\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/d9/66/bde66382496710218c0df31b5f3a72bd8079bcd275fff61b29\n",
            "  Building wheel for billiard (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for billiard: filename=billiard-3.5.0.5-cp36-none-any.whl size=87882 sha256=2deb3c44ce24590a9f76101f8db27e74c73a906bc74b881ccaebd3e2f6937b9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/72/0e/39ecdedc4cfc45b693a623732e40dbd4cff5ea5e11775ee591\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for args: filename=args-0.1.0-cp36-none-any.whl size=3320 sha256=a8b8e1944e0dbd7088675d3d756053de6dc4a9cdcd1462d5dac7bc6498f07ce6\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/54/ea/d995d18af68c057eb76b87b02c92bc66ac34d360ef141780f4\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609222 sha256=7408718db5d63bc973bf1d0e8350fc81a6e991c0d2f18f0e1fef7edd627f2ddd\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built uspto-opendata-python clint awesome-slugify billiard args regex\n",
            "\u001b[31mERROR: tfds-nightly 1.2.0.dev201908260105 has requirement requests>=2.19.0, but you'll have requests 2.18.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.18.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: billiard, vine, amqp, kombu, celery, idna, urllib3, requests, redis, beautifulsoup4, pathvalidate, lxml, jsonpointer, args, clint, regex, Unidecode, awesome-slugify, uspto-opendata-python\n",
            "  Found existing installation: idna 2.8\n",
            "    Uninstalling idna-2.8:\n",
            "      Successfully uninstalled idna-2.8\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed Unidecode-0.4.21 amqp-2.5.1 args-0.1.0 awesome-slugify-1.6.5 beautifulsoup4-4.6.0 billiard-3.5.0.5 celery-4.1.0 clint-0.5.1 idna-2.6 jsonpointer-1.12 kombu-4.6.4 lxml-4.2.5 pathvalidate-0.16.2 redis-2.10.6 regex-2019.8.19 requests-2.18.4 urllib3-1.22 uspto-opendata-python-0.8.3 vine-1.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6UnJ9c-icrX",
        "colab_type": "code",
        "outputId": "f0aacd77-787c-4a1c-91e5-3693d02aa063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "import os\n",
        "import nltk.data\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "import itertools\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "from autocorrect import spell \n",
        "\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "import requests\n",
        "from pandas.io.json import json_normalize\n",
        "import json\n",
        "\n",
        "os.chdir('/content/usptoSearch')\n",
        "os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/usptoSearch'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUauuRCSmAu6",
        "colab_type": "code",
        "outputId": "779461ba-26c5-41c0-d79e-db25a1918b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#import data\n",
        "df = pd.read_csv('usptoSubsetData.csv')\n",
        "print(len(df))\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat_no</th>\n",
              "      <th>claim_no</th>\n",
              "      <th>claim_txt</th>\n",
              "      <th>dependencies</th>\n",
              "      <th>ind_flg</th>\n",
              "      <th>appl_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>2</td>\n",
              "      <td>2. The process of claim 1, wherein in process ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039651</td>\n",
              "      <td>1</td>\n",
              "      <td>1. In the process for the production of hydrog...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4039652</td>\n",
              "      <td>23</td>\n",
              "      <td>23. A method as in claim 1 wherein said substa...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5405316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4039652</td>\n",
              "      <td>29</td>\n",
              "      <td>29. A method as in claim 26 wherein said immob...</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>5405316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4039652</td>\n",
              "      <td>24</td>\n",
              "      <td>24. A method as in claim 23 wherein said subst...</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>5405316.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pat_no  claim_no  ... ind_flg    appl_id\n",
              "0  4039651         2  ...       0        NaN\n",
              "1  4039651         1  ...       1        NaN\n",
              "2  4039652        23  ...       0  5405316.0\n",
              "3  4039652        29  ...       0  5405316.0\n",
              "4  4039652        24  ...       0  5405316.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC7l1cr-y9V5",
        "colab_type": "code",
        "outputId": "c81b1767-f2a9-4cae-9cd7-49098ed13756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "df1=df.copy()\n",
        "#concatenate claims by patent number\n",
        "df2 = df1.sort_values(['pat_no', 'claim_no']).groupby('pat_no', sort=False).claim_txt.apply(' '.join).reset_index(name='concat_claims')\n",
        "df2.to_csv('concatenated.csv')\n",
        "print(len(df))\n",
        "df2.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat_no</th>\n",
              "      <th>concat_claims</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>1. In the process for the production of hydrog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039652</td>\n",
              "      <td>1. A method for the quantitative determination...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4039653</td>\n",
              "      <td>1. A tablet for releasing a relatively uniform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4039654</td>\n",
              "      <td>1. A prostanoic acid derivative of the formula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4039655</td>\n",
              "      <td>1. A composition of matter useful in caries pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pat_no                                      concat_claims\n",
              "0  4039651  1. In the process for the production of hydrog...\n",
              "1  4039652  1. A method for the quantitative determination...\n",
              "2  4039653  1. A tablet for releasing a relatively uniform...\n",
              "3  4039654  1. A prostanoic acid derivative of the formula...\n",
              "4  4039655  1. A composition of matter useful in caries pr..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ieq_q8VknkI",
        "colab_type": "code",
        "outputId": "5397aedb-45f4-411d-b7b2-901c0354e125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df3 = df2.copy()\n",
        "df3['processed'] = df3['concat_claims']\n",
        "\n",
        "#preprocess data\n",
        "stemmer = SnowballStemmer('english')   #snowball stemmer chosen over porter due for its aggressiveness\n",
        "\n",
        "#preprocess data\n",
        "df3['processed'] = df3['processed'].str.replace('\\d+', '') #remove digits\n",
        "df3['processed'] = df3['processed'].str.replace('[^\\w\\s]','') #remove punctuation\n",
        "df3['processed'] = df3['processed'].str.lower() #lowercase\n",
        "#df3['processed'] = df3['processed'].apply(lambda x: \" \".join([spell(i) for i in x.split()]))   #spellcheck             #computationally too intensive\n",
        "df3['processed']= df3['processed'].apply(treebank_tokenizer.tokenize) #tokenize\n",
        "df3['processed'] = df3['processed'].apply(lambda x: [y for y in x if y not in stop]) #remove stop words\n",
        "#df3['processed'] = df3['processed'].apply(lambda x: [wordnet_lemmatizer.lemmatize(item) for item in x]) #lemmatize    #stemming chosen over lemmatize\n",
        "df3['processed'] = df3['processed'].apply(lambda x: [stemmer.stem(item) for item in x]) #stem\n",
        "df3.head()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat_no</th>\n",
              "      <th>concat_claims</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>1. In the process for the production of hydrog...</td>\n",
              "      <td>[process, product, hydrogen, oxygen, water, me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039652</td>\n",
              "      <td>1. A method for the quantitative determination...</td>\n",
              "      <td>[method, quantit, determin, specif, bind, subs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4039653</td>\n",
              "      <td>1. A tablet for releasing a relatively uniform...</td>\n",
              "      <td>[tablet, releas, relat, uniform, quantiti, med...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4039654</td>\n",
              "      <td>1. A prostanoic acid derivative of the formula...</td>\n",
              "      <td>[prostano, acid, deriv, formula, str, wherein,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4039655</td>\n",
              "      <td>1. A composition of matter useful in caries pr...</td>\n",
              "      <td>[composit, matter, use, cari, prevent, compris...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pat_no  ...                                          processed\n",
              "0  4039651  ...  [process, product, hydrogen, oxygen, water, me...\n",
              "1  4039652  ...  [method, quantit, determin, specif, bind, subs...\n",
              "2  4039653  ...  [tablet, releas, relat, uniform, quantiti, med...\n",
              "3  4039654  ...  [prostano, acid, deriv, formula, str, wherein,...\n",
              "4  4039655  ...  [composit, matter, use, cari, prevent, compris...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncGRhwOo6OOk",
        "colab_type": "code",
        "outputId": "386ee0bf-5da3-44b3-9c42-d1777d3db026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#create keyword list of 40 of the most commonly used words\n",
        "df4=df3.copy()\n",
        "df4['keywords'] = df4['processed'].apply(lambda x: [k for k, v in Counter(x).most_common(30)])\n",
        "dfIndex = df4\n",
        "dfIndex.to_csv('patentIndex.csv')\n",
        "dfIndex = df4.drop(['concat_claims'], axis=1)\n",
        "dfIndex.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pat_no</th>\n",
              "      <th>processed</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4039651</td>\n",
              "      <td>[process, product, hydrogen, oxygen, water, me...</td>\n",
              "      <td>[iron, oxid, chlorid, step, ii, process, hydro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4039652</td>\n",
              "      <td>[method, quantit, determin, specif, bind, subs...</td>\n",
              "      <td>[said, matrix, sampl, wherein, method, predete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4039653</td>\n",
              "      <td>[tablet, releas, relat, uniform, quantiti, med...</td>\n",
              "      <td>[tablet, said, materi, medica, releas, odormas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4039654</td>\n",
              "      <td>[prostano, acid, deriv, formula, str, wherein,...</td>\n",
              "      <td>[rsup, acid, prostano, deriv, hydrogen, claim,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4039655</td>\n",
              "      <td>[composit, matter, use, cari, prevent, compris...</td>\n",
              "      <td>[group, compound, said, composit, oral, german...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    pat_no  ...                                           keywords\n",
              "0  4039651  ...  [iron, oxid, chlorid, step, ii, process, hydro...\n",
              "1  4039652  ...  [said, matrix, sampl, wherein, method, predete...\n",
              "2  4039653  ...  [tablet, said, materi, medica, releas, odormas...\n",
              "3  4039654  ...  [rsup, acid, prostano, deriv, hydrogen, claim,...\n",
              "4  4039655  ...  [group, compound, said, composit, oral, german...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J28OD_3fGmy9",
        "colab_type": "code",
        "outputId": "66967c88-86e5-4ae0-81f7-b30b02f44e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#search term processing\n",
        "#aggressive spellchecker/autocorrect simplifies search\n",
        "#but has obvious limitations \n",
        "\n",
        "#rawSearch=(input('Enter your search:')) #for front end development or demoing\n",
        "rawSearch = 'liquid1 crystalss displaying'\n",
        "\n",
        "\n",
        "def searchPreprocessing(rawSearch):\n",
        "  stemmer = SnowballStemmer('english')\n",
        "  \n",
        "  searchQuery = rawSearch\n",
        "  searchQuery = searchQuery.lower()\n",
        "  searchQuery = ' '.join(map(spell, searchQuery.split()))\n",
        "  searchQuery = searchQuery.replace('[^\\w\\s]','')\n",
        "  searchQuery = searchQuery.replace('\\d+', '')\n",
        "  searchQuery = searchQuery.lower()\n",
        "  searchQuery = treebank_tokenizer.tokenize(searchQuery)\n",
        "  searchQuery = [word for word in searchQuery if word not in stopwords.words('english')]\n",
        "  searchQuery = [stemmer.stem(word) for word in searchQuery]\n",
        "  \n",
        "  print(\"Searching '\" + str(rawSearch) + \"' as: \" + str(searchQuery))\n",
        "  return searchQuery\n",
        "  \n",
        "\n",
        "searchQuery = searchPreprocessing(rawSearch)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching 'liquid1 crystalss displaying' as: ['liquid', 'crystal', 'display']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8EK_iUN-BSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define cosine similarity function\n",
        "def cosine_similarity(document_1_data, document_2_data):\n",
        "    def stringify(whatever):\n",
        "        newString = \" \".join(whatever)\n",
        "        return newString\n",
        "    \n",
        "    \n",
        "    WORD = re.compile(r'\\w+') \n",
        "    \n",
        "    def get_cosine(vec1, vec2):\n",
        "        intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "        numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "        sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "        sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "        denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "        \n",
        "        if not denominator:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return float(numerator) / denominator\n",
        "        \n",
        "    def text_to_vector(text):\n",
        "        words = WORD.findall(text)\n",
        "        return Counter(words)\n",
        "    \n",
        "    text1 = stringify(document_1_data)\n",
        "    text2 = stringify(document_2_data)\n",
        "    \n",
        "    vector1 = text_to_vector(text1)\n",
        "    vector2 = text_to_vector(text2)\n",
        "    \n",
        "    cosine = get_cosine(vector1, vector2)\n",
        "    \n",
        "    return(cosine)\n",
        "\n",
        "    \n",
        "#test   \n",
        "#doc1=searchQuery\n",
        "#doc2=dfIndex.iloc[0,1]\n",
        "#cosine_similarity(doc1, doc2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guET-mR2CLwG",
        "colab_type": "code",
        "outputId": "789ff92a-a078-4213-8700-d243001749c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "#find cosine values and rank them\n",
        "searchRank = []\n",
        "doc1=searchQuery\n",
        "\n",
        "for index, row in dfIndex.iterrows():\n",
        "  doc2 = dfIndex.iloc[index,1]\n",
        "  procesCos = (cosine_similarity(doc1,doc2))\n",
        "  doc2 = dfIndex.iloc[index,2]\n",
        "  keyworCos = (cosine_similarity(doc1,doc2))\n",
        "  temp = (dfIndex.iloc[index,0], procesCos, keyworCos)\n",
        "  searchRank.append(temp)\n",
        "\n",
        "\n",
        "searchRank=pd.DataFrame(searchRank ,columns=['patNo', 'processedCosRank', 'keywordCosRank'])\n",
        "\n",
        "\n",
        "#rank by processed tokens\n",
        "#searchRank = searchRank.sort_values(by=['processedCosRank'], ascending=False)\n",
        "#rank by keyword matches\n",
        "searchRank = searchRank.sort_values(by=['keywordCosRank'], ascending=False)\n",
        "searchRank.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patNo</th>\n",
              "      <th>processedCosRank</th>\n",
              "      <th>keywordCosRank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1067</th>\n",
              "      <td>4040719</td>\n",
              "      <td>0.245722</td>\n",
              "      <td>0.316228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>4040720</td>\n",
              "      <td>0.181273</td>\n",
              "      <td>0.316228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>4040047</td>\n",
              "      <td>0.081920</td>\n",
              "      <td>0.210819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>4039890</td>\n",
              "      <td>0.162805</td>\n",
              "      <td>0.210819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>4039803</td>\n",
              "      <td>0.286308</td>\n",
              "      <td>0.210819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>4040171</td>\n",
              "      <td>0.124452</td>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>4040567</td>\n",
              "      <td>0.305293</td>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>4040421</td>\n",
              "      <td>0.049108</td>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>4040088</td>\n",
              "      <td>0.047730</td>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>4039899</td>\n",
              "      <td>0.026145</td>\n",
              "      <td>0.105409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        patNo  processedCosRank  keywordCosRank\n",
              "1067  4040719          0.245722        0.316228\n",
              "1068  4040720          0.181273        0.316228\n",
              "396   4040047          0.081920        0.210819\n",
              "239   4039890          0.162805        0.210819\n",
              "152   4039803          0.286308        0.210819\n",
              "520   4040171          0.124452        0.105409\n",
              "915   4040567          0.305293        0.105409\n",
              "769   4040421          0.049108        0.105409\n",
              "437   4040088          0.047730        0.105409\n",
              "248   4039899          0.026145        0.105409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqgizBdDxtJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "d8c25ca1-1e58-45d6-e984-d8be3c1f36aa"
      },
      "source": [
        "patNo = str(searchRank.iloc[0,0])\n",
        "\n",
        "url = 'http://www.patentsview.org/api/patents/query?q={\"patent_number\":\"'+ patNo + '\"}&f=[\"inventor_first_name\",\"inventor_last_name\",\"patent_number\", \"patent_title\", \"assignee_country\",\"assignee_organization\", \"examiner_id\", \"examiner_last_name\"]'\n",
        "\n",
        "r = requests.get(url)\n",
        "json_data = r.json()\n",
        "\n",
        "for r in json_data['patents']:\n",
        "    print(r)\n",
        "\n",
        "print(json.dumps(json_data, sort_keys=True, indent=0))\n",
        "\n",
        "print('Full Text:')\n",
        "fullText = df2.loc[df2['pat_no'] == int(patNo),'concat_claims']\n",
        "print(list(fullText))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'patent_number': '4040719', 'patent_title': 'Frequency indicator for receiving devices', 'inventors': [{'inventor_first_name': 'Heinz F.', 'inventor_last_name': 'Schiebelhuth', 'inventor_key_id': '232734'}], 'assignees': [{'assignee_country': None, 'assignee_organization': None, 'assignee_key_id': None}], 'examiners': [{'examiner_id': '87vxycv5jpvf3o4l0wam0g34z', 'examiner_last_name': 'Corbin'}, {'examiner_id': 'ljfgrp5jxfn12mag4p4rjp5da', 'examiner_last_name': 'Hille'}]}\n",
            "{\n",
            "\"count\": 1,\n",
            "\"patents\": [\n",
            "{\n",
            "\"assignees\": [\n",
            "{\n",
            "\"assignee_country\": null,\n",
            "\"assignee_key_id\": null,\n",
            "\"assignee_organization\": null\n",
            "}\n",
            "],\n",
            "\"examiners\": [\n",
            "{\n",
            "\"examiner_id\": \"87vxycv5jpvf3o4l0wam0g34z\",\n",
            "\"examiner_last_name\": \"Corbin\"\n",
            "},\n",
            "{\n",
            "\"examiner_id\": \"ljfgrp5jxfn12mag4p4rjp5da\",\n",
            "\"examiner_last_name\": \"Hille\"\n",
            "}\n",
            "],\n",
            "\"inventors\": [\n",
            "{\n",
            "\"inventor_first_name\": \"Heinz F.\",\n",
            "\"inventor_key_id\": \"232734\",\n",
            "\"inventor_last_name\": \"Schiebelhuth\"\n",
            "}\n",
            "],\n",
            "\"patent_number\": \"4040719\",\n",
            "\"patent_title\": \"Frequency indicator for receiving devices\"\n",
            "}\n",
            "],\n",
            "\"total_patent_count\": 1\n",
            "}\n",
            "Full Text:\n",
            "['1. A display panel having a plurality of liquid crystal elements arranged to indicate operating frequency of signal receiving means being tuned by a DC analog tuning signal having a continuously variable magnitude comprising:logarithmic analog-to-digital converter means for converting said analog tuning signal to digitally coded signals;decoder means responsive to said digitally coded signals for providing digital control signals; andmeans for converting said digital control signals to an alternating current signal for operating said liquid crystal elements. 2. A display panel according to claim 1, wherein said analog-to-digital converter means operates according to a duel-slope process. 3. A display panel according to claim 1, wherein said digitally coded signals is in BCD code. 4. A display panel according to claim 1, wherein said means for converting said digital control signals to said alternating current control signal is an exclusive OR gate. 5. A display panel for indicating operating frequency of a radio receiver, comprising:a plurality of liquid crystal elements;decoder means;logarithmic analog-to-digital converter means for providing digitally coded signals to said decoder means, said decoder means responding to said coded signals to provide control signals for said liquid crystal elements;voltage tunable oscillator means responsive to a DC analog tuning voltage for varying said operating frequency of said radio receiver, said analog tuning voltage being coupled to said means for providing digitally coded signals to said decoder means, andmeans for converting said control signals to an alternating current signal and applying said alternating current signals to said liquid crystal elements to display said radio receiver operating frequency. 6. A liquid crystal display apparatus for indicating operating frequency of a radio receiver, said apparatus being responsive to a DC analog tuning signal determining said radio receiver operating frequency, comprising:logarithmic analog-to-digital converter means for converting said analog tuning signals to digitally coded signals;decoder means responsive to said digitally coded signals for providing digital control signals; andmeans for converting said digital control signals to an alternating current signal for operating said liquid crystal display apparatus to indicate said radio receiver operating frequency.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZPkmhYXCfwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#keywords = dfIndex['keywords']\n",
        "#keywords.head()\n",
        "\n",
        "#fuzzywuzzy keyword matching not great\n",
        "#process.extract(str(searchQuery), keywords, limit=4, scorer=fuzz.token_sort_ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P9bZcGgxhoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Doesn't work on many patents. Using PatentView API Instead\n",
        "#from uspto.peds.client import UsptoPatentExaminationDataSystemClient\n",
        "#client = UsptoPatentExaminationDataSystemClient()\n",
        "\n",
        "#result = client.download_document('3987485')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}